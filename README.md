# Psychologists courses

This is a sandbox pet project with backend graphql api built on Go's [gqlgen](https://github.com/99designs/gqlgen)
library.

# Prerequisites

- docker (for postgres)
- Go
- linux (for Makefile)

# Tech stack

- Go 1.22
- gqlgen
- bun for main database manipulations
- pgxpool for migrations
- Postgres ([deployment](docker-deployments/docker-compose.pg.yml))

# Short explanation

Purpose of this api is to create, read and update entities that are specified by domain.
Graphql has many purposes, but in this project it's used to interact with database.

Core entities:

- psychologist
- course
- lesson

Psychologists and courses have many-to-many data model. So, psychologist can have many courses and vice versa.\
Course and lessons have one-to-many data model. So, one course has many lessons.\
Api has queries and mutations described in [graphql schema](graph/schema.graphqls), so client can get all the entities
at
once or single by id, insert by values or update by id.

Tables migration file [here](migrations/sql/up.sql) can be used as reference for entity relations.
Data migration can be found [here](migrations/sql/data.sql)

# Technical explanation

This project uses graphql library named `gqlgen` that generates code from [graphql schema](graph/schema.graphqls).
`Gqlgen` configuration for generating is almost default for this library and stored in [gqlgen.yml](gqlgen.yml) file.
The most
important change in this file is `autobind` property that leads to [bunmodels](bunmodels) folder and allows to use
manually created bun models instead of generated. This approach simplifies interaction between graphql models and
database and reuse one model for both sides. But this approach is used only for `Query` models and doesn't spread on
`Mutations`, where models are still generated by `gqlgen`.

It's not so clear, but to generate `field resolver` - `@goField(forceResolver: true)` directive must be added in gql
schema after field where it's needed.

Entry point of the entire program is [server.go](server.go) where described all initialization and dependency injection.
The program has custom logger (`zerolog`), `bun` as ORM, [entman](entman) as business logic layer and `http server` from
default `net/http` package.
Server runs generated code, which in turn runs resolvers. Resolvers in this project will be used for
authorization and context manipulation in the future, but now are used only to call [EntityManager](entman/entman.go)
that implements all the business logic.

Project preset to work with makefile, so envs examples can be seen [here](Makefile).

# Local run

Current project requires data (at least tables) to be loaded in postgres before working.\
Steps to deploy current project on your machine (some steps can be done simply using [Makefile](Makefile), but if you
use Windows or system without `make`, you can use commands inside as cheatsheet):

- deploy postgres using docker (make deploy-pg). Credentials are
  in [deployment file](docker-deployments/docker-compose.pg.yml), so you can use them for db connection
- migrate data (make migrate). It will create necessary [tables](migrations/sql/up.sql) and fill them
  with [data](migrations/sql/data.sql)
- run graphql server (make run) and try to retrieve/insert/update data. Now server can be accessed
  on http://localhost:8080

# Local development

This section describes how to change logic and run changes.\
Steps of execution:

- [optionally] change graphql schema and migrations with data for your needs
- execute first 2 points of [Local run](#local-run) section (deploy pg and migrate data)
- change resolvers and entity manager logic, but don't touch [generated](graph/generated.go) code as changes will be
  erased by generator
- generate code (make gql-gen)
- run graphql server (make run). Now server can be accessed on http://localhost:8080

[schema.resolvers](graph/schema.resolvers.go) file can be changed by generator, but the library will allow you to save
code for fundamentally changed types in `graphql schema` even after generation.
